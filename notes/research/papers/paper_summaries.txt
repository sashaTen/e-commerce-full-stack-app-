"financial question answering," "small language models," "financial reasoning," "FinQA dataset,"   "reasoning  in   language  models". 

..........FINQA   :
*the   problem  is   :   analyzys    automation   in  qa 
*also the  reasonging   in  QA  is    veyr   simple 
and  one  step.  
* the   question   is  -    how this  proccess  can  be  dome  better   ? 
*All you need to know about Question-Answering (QA) systems built using NLP: 
QA systems use a variety of techniques, including natural language understanding, information retrieval,
 and machine learning,
  to extract the relevant information from a given text corpus
 and generate an answer to a userâ€™s question.
open  resources  and  closed  resource  types .

--domain    based   QA  is  my  focus .
https://www.unthinkable.co/blog/all-you-need-to-know-about-question-answering-qa-systems-built-using-nlp/
*RAG  AND  IR   MECHANISMS 
*The two main techniques for adaptation are fine-tuning and retrieval-augmented generation (RAG).
Fine-Tuning Techniques and Methods:
.full   fine tuning 
.adapter  based 
.promt  based 
.distillation
.sparse   / low rank  /  prunning
*Introduction to Retrieval Augmentation:
https://medium.com/@bijit211987/fine-tuning-and-rag-tailoring-language-models-to-your-needs-69ca9e1c2c70
FinQANet (RoBERTa-large) 61.24 58.8

........A Numerical Reasoning Question Answering System with Fine-grained
Retriever and the Ensemble of Multiple Generators for FINQA

69%
*later    you  will  have to   analyse  the  dataset   
as  well  as  to  read   paper    again .
* test set in FinQA
Competition.  that  is  the  goal  .
*they  use   Ensemble   generators .
*later     you  will  have to   read   paper   in  depth  so  
you learn all the   prerequisites .
-  maybe   you  can  for  the   Ensemble language  models :
https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/



....................DeBERTa   for  finqa 
We use the method based on DeBERTa pre-trained language model, with additional optimization methods including multimodel fusion, training set combination on this
basis. We finally obtain an execution accuracy of 68.99 and a program accuracy of 64.53,
. Existing Q&A systems are mainly divided into two
mainstream categories, retrieval based Q&A systems and generation based Q&A systems.
*The system used a pre-trained language model called DeBERTa as its foundation.
To improve performance, the system employed additional techniques:
Multimodel fusion: Combining information from different sources within the model.
Training set combination: Using various datasets for training to enhance the system's knowledge and capabilities.

*finally achieve the execution accuracy
of 68.99 after fine-turning and optimization, and
win the fourth prize in the FinQA challenge

*generally they  used  different   model  fusions  


...............ELASTIC: Numerical Reasoning with
Adaptive Symbolic Compiler

numEricaL reASoning with adapTive symbolIc Compiler (ELASTIC) model,
which is constituted of the RoBERTa as the Encoder and a Compiler with four
modules: Reasoning Manager, Operator Generator, Operands Generator, and
Memory Register:   
68%    finqa  and    mathQA    
it  is   domain    agnistic .
...........Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks
